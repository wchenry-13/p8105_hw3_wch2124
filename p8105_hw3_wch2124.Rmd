---
title: "hw3"
output: html_document
date: '2023-10-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

This data set consists of 1,384,617 observations of 15 variables. Some key variables include product ID, department, and product name. The user ID's appear to be grouped by order number, which makes sense because when you order on Instacart, you are given a unique order number that corresponds to your unique user ID. 
```{r}
library(tidyverse)
library(dplyr)
library(p8105.datasets)
data("instacart")

## how many aisles are there and which aisles are the most items ordered from?

#instacart_data = 
  #instacart |> 
  #as_tibble()
  
#group_by(aisle) |>
  #summarize(n_obs = n())

## make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

#ggplot(instacart_data, aes(x = add_to_cart_order, y = aisle)) + geom_point()
  
  
```

## Problem 2

```{r}
data("brfss_smart2010")

## data cleaning 

  brfss_smart2010 =
  brfss_smart2010 |>     
  janitor::clean_names() |> 
  filter(
    topic == "Overall Health",
    response %in% c("Excellent","Very good", "Good", "Fair", "Poor")) |> 
  mutate( 
    response = 
      fct_relevel(response, c("Poor", "Fair", "Good","Very good","Excellent" ))
  )
  brfss_smart2010


```

## in 2002, which states were observed at 7 or more locations? What about in 2010?

```{r}
states_obs <- brfss_smart2010 |> 
  filter(year %in% c(2002, 2010)) |> 
  select(year, locationabbr, locationdesc) |> 
  distinct() |> 
   group_by(year, locationabbr) |>
  summarize(n = n()) |> 
  filter(n >= 7) |> 
  arrange(year, desc(n))
```

## Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.

```{r}  
excellent_data <- brfss_smart2010 |> 
  filter(response %in% c("Excellent")) |>
  select(year, locationabbr, data_value) |>
  group_by(locationabbr, year) |> 
  mutate(
    avg_data_value = mean(data_value)) |> 
  select(year, locationabbr, avg_data_value) |> 
  distinct()
```

## spaghetti plot

```{r}
excellent_data |> 
  ggplot(aes(x = year, y = avg_data_value)) +
  geom_line(aes(group = locationabbr, color = locationabbr))

```

## make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State

```{r}
brfss_smart2010 |> 
  select(year, data_value, locationabbr, locationdesc, response) |> 
  filter(
    year == 2006 | year == 2010,
    locationabbr == "NY") |> 
  ggplot(aes(x = data_value, fill = response)) +
  geom_boxplot(aes(fill = response), alpha = .5) +
  facet_grid(. ~ year)
```

## Problem 3 

```{r}
## load, tidy, merge, and otherwise organize the data sets.

covar_data <- read.csv("nhanes_covar.csv", sep = '\t', skip = 4, col.names = c("seqn", "SEQN"))
accel_data <- read.csv("nhanes_accel.csv")

covar_data_clean = covar_data |> 
  drop_na() |> 
  janitor::clean_names() |> 
  mutate(
    sex = recode(sex, '1' = "male", '2' = "female"),
    education = recode(education, '1' = "less than high school", '2' = "high school equivalent", '3' = "more than high school")) |> 
  mutate(education = factor(education, levels = c("less than high school", "high school equivalent", "more than high")))
  filter(age > 21)
  
merged_df = 
  covar_data_clean |> 
  left_join(accel_data_clean, by = "seqn")
```

## Produce a reader-friendly table for the number of men and women in each education category, and create a visualization of the age distributions for men and women in each education category

```{r}
merged_df |>
  drop_na() |> 
  group_by(sex, education) |>
  summarize(count = n()) |> 
  knitr::kable(digits = 1)  

merged_df |>
  drop_na() |> 
  ggplot(aes(x = age, fill = education)) +
  geom_histogram()

```

## Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities

```{r}

  

```

