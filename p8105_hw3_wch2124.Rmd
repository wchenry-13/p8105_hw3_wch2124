---
title: "hw3"
output: html_document
date: '2023-10-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem 1

This data set consists of 1,384,617 observations of 15 variables. Some key variables include product ID, department, and product name. The user ID's appear to be grouped by order number, which makes sense because when you order on Instacart, you are given a unique order number that corresponds to your unique user ID. 
```{r}
library(tidyverse)
library(dplyr)
library(p8105.datasets)
data("instacart")

## how many aisles are there and which aisles are the most items ordered from?

#instacart_data = 
  #instacart |> 
  #as_tibble()
  
#group_by(aisle) |>
  #summarize(n_obs = n())

## make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

#ggplot(instacart_data, aes(x = add_to_cart_order, y = aisle)) + geom_point()
  
  
```

## Problem 2

```{r}
data("brfss_smart2010")

## data cleaning 

  brfss_smart2010 =
  brfss_smart2010 |>     
  janitor::clean_names() |> 
  filter(
    topic == "Overall Health",
    response %in% c("Excellent", "Good", "Fair", "Poor")) |> 
  mutate( 
    response = 
      fct_relevel(response, c("Poor", "Fair", "Good","Excellent" ))
  )
  brfss_smart2010



## in 2002, which states were observed at 7 or more locations? What about in 2010?

states_obs <- brfss_smart2010 |> 
  filter(year %in% c(2002, 2010)) |> 
  select(year, locationabbr, locationdesc) |> 
  distinct() |> 
   group_by(year, locationabbr) |>
  summarize(n = n()) |> 
  filter(n >= 7) |> 
  arrange(year, desc(n))
  
## Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state.

excellent_data <- brfss_smart2010 |> 
  filter(response %in% c("Excellent")) |>
  select(year, locationabbr, data_value) |>
  group_by(locationabbr, year) |> 
  mutate(
    avg_data_value = mean(data_value)) |> 
  select(year, locationabbr, avg_data_value) |> 
  distinct()

excellent_data |> 
  ggplot(aes(x = year, y = avg_data_value)) +
  geom_line(aes(group = locationabbr, color = locationabbr))

## make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State

#states_obs |> 
 # select(year, data_value, locationabbr, locationdesc, response_ordered) |> 
  #filter(
   # year == 2006 | year == 2010,
   # locationabbr == "NY") |> 
  #ggplot(aes(x = data_value, fill = response_ordered)) +
  #geom_density(aes(fill = response_ordered), alpha = .5)

```

## Problem 3 

```{r}
## load, tidy, merge, and otherwise organize the data sets.
covar_data = read.csv("nhanes_covar.csv")
accel_data = read.csv("nhanes_accel.csv")


```

